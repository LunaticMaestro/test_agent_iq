general:
  use_uvloop: true
  logging:
    console:
      _type: console
      level: WARN

  front_end:
    _type: fastapi

  front_end:
    _type: console

llms: 
  nim_llm: 
    _type: nim
    model_name: meta/llama-3.1-70b-instruct
    temperature: 0.0
    max_tokens: 1024

workflow:
  _type: python_express_executor
  parameter: default_value